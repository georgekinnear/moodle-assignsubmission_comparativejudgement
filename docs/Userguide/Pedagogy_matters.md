# Pedagogy matters

Comparative judgement is a simple idea: compare pairs of work and produce a score for each piece of work. This simplicity means that the comparative judgement Moodle plug-in is a very flexible tool that can be used in all sorts of ways. On this page we 
* cover the basics of using comparative judgement for **summative assessment**.
* provide an **example use case**, based on how one of the developers of the plug-in uses it.
* consider issues such as **how to criterion reference scores**, and how to provide **feedback to students**.
* summarise some published studies from across various subjects in reporting uses of **comparative judgemt in higher education**.

# 1. Summative assessment.
The plug-in has been designed with summative assessment in mind. See the [user guide](https://github.com/ianjones/moodle-assignsubmission_comparativejudgement/blob/master/docs/Userguide/Using_the_CJ_plugin.md) for the technicalities of setting up a summative assessment. Here we will focus on a high-level of overview.

There are three parts to using the plug-in for summative assessment.

## i) Administer an assessment task.
Set the students an open-ended or performance-based task that you plan to assess. This might be a piece of extended writing, an e-Portfolio of a design project, a movie file of a presentation, and any other complex piece of work than can be captured as a computer file (see **Section 5**, below, for further examples). Remember that the comparative judgement is well-suited to assessing complicated pieces of work that vary greatly from student to student; if you have more restricted or standardised pieces of work to assess then comparative judgement might not be for you. 

## ii) Assess the task.
There are three parts to assessing the task. First, set up an **Assignment** activity in Moodle, as detailed [here](https://github.com/ianjones/moodle-assignsubmission_comparativejudgement/blob/master/docs/Userguide/Using_the_CJ_plugin.md).

Second, students submit their work via the **Assignment** link.

Third, students make pairwise comparisons of their peers' work (about 20 per student), and the teacher also contributes some pairwise comparisons for moderation purposes (about twice as many comparisons as the number of students on the module is recommended). Students are told that their final score will depend entirely on the quality of their work as moderated by the lecturer, but that their score will not be released to them unless they complete their comparisons in full.

## ii) Get the scores.
Once enough comparisons have been collected, and a minimum of 10 comparisons per submission is recommended, the for each submission can be calculated, as detailed [here](https://github.com/ianjones/moodle-assignsubmission_comparativejudgement/blob/master/docs/Userguide/Using_the_CJ_plugin.md). You are likely to want to ensure the scores are criterion referenced, and to know where to put the grade boundaries, before providing the scores to students. See **Section 3** below on how to do this. 

That's the bare bones, but in practice a motivation for using comparative judgement in higher education isn't just to assess complex, varied pieces of work for summative purposes. It is also to promote deep learning through engaging students with peer assessment and peer feedback activities, and this is described in **Section 4** below.

# 2. Example use case.
Comparative judgement has been used for several years on mathematics modules at Loughborough University. This section gives a high-level overview of typical usage, for the case of a Foundation Mathematics module. 

Early in the module, usually in the first lecture, students are first presented with an open-ended prompt, such as 

>*What is an equation? Give examples of how equations can be useful* 

at the top of a blank page. Such open-ended tasks are usually unfamiliar to students in mathematics, and they are asked to answer as best they can using writing, diagrams and symbols. They are given about ten minutes to answer in test conditions, and then submit their responses via an **Assignment** link in Moodle.

In the subsequent lecture, which might take place in a computer lab or using students' own devices, the students are then instructed to complete 10 comparisons of their peers' (anonymised). The students are told that for each pairing they should choose, for the case of this example, *the better understanding of equation*. Students are told to discuss and justify their decisions within one another whilst making comparisons, and they typically do this in groups of two or three.

Once the comparisons are complete the lecturer facilitates a whole class discussion in which students share what they think distinguishes better quality responses from the responses that were not so good. For the case of open-ended prompts in mathematics similar conclusions usually arise, for example that better quality responses use a range of representations (prose, equations, graphs, diagrams), tend not contain mathematical errors, contain worked through examples and so on. 

The above activity is repeated three or four times over the duration of a module, with different questions. As the summative test nears towards the end of the module the students are told that the best way to revise is to practice the questions, upload their practice responses, and to continue making comparisons of their peers' work (there is no limit on how many comparisons they can make once an **Assignment** is set up on Moodle). It is common in revision sessions to see students choosing to revisit the comparative judgement activities in small groups to discuss and make notes on how to produce high-quality responses. 

# 3. How to criterion reference scores.


# 4. Feedback to students.


# 5. Comparative judgemt in higher education.


