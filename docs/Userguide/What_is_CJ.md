# Comparative judgement
Comparative judgement (CJ) is a holistic approach to educational assessment that involves no rubrics, no marking and no assessor training. Instead, assessors are presented with two pieces of student work and asked simply to decide which is ‘better’ in terms of a high-level criterion such as *problem solving* or *quality of writing*. Many pairwise comparisons from a group of assessors are then fitted to a statistical model to produce a score for each piece of work.

Comparative judgement is particularly useful for *reliably assessing complex and varied pieces of student work* that do not lend themselves to being captured in a rubric. Such work might include creative writing, performance pieces and student design projects. Research has shown that assessors are consistent at making pairwise comparisons of such student work. This consistency enables us to produce reliable and valid scores where traditioanl rubric-based marking methods often fail. There is a corpus of published research that used comparative judgement in higher education contexts, for example in [mathematics](http://dx.doi.org/10.1080/03075079.2013.821974) and [writing](http://dx.doi.org/10.1080/03075079.2013.821974). 

The lack of need for assessor training means that comparative judgement is also well suited to *peer assessment*, and this Moodle plug-in has been designed with peer assessment in mind. Students upload their own work through the Assessment resource, and can then make comparisons of their peers work. For more examples of research exploring the use of comparative judgement in mathematics education, in a variety of contexts including with peer assessment, see [Ian Jones's webpage](https://iansajones.wordpress.com). 

